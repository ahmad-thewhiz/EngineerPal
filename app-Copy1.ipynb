{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cdf40eb2-6b35-445b-90c7-7747226b7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from Files.csvLoader import loadCSV\n",
    "from Files.docsLoader import loadDOCS\n",
    "from Files.htmlLoader import loadHTML\n",
    "from Files.jsonLoader import loadJSON\n",
    "from Files.mdLoader import loadMD\n",
    "from Files.pdfLoader import loadPDF\n",
    "from Files.txtLoader import loadTXT\n",
    "\n",
    "from Websites.urlLoader import loadURL\n",
    "from Websites.seleniumLoader import loadSELENIUM\n",
    "from Websites.recursiveLoader import loadRECURSIVE\n",
    "\n",
    "from Youtube.youtubeLoader import loadYOUTUBE\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aafc93a2-9a27-47af-9ea3-78a6fc1aa72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ad6c0fa-779e-4fea-b58f-85d9eafe42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file_path: str):\n",
    "    try:\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            return loadPDF(file_path)\n",
    "        elif file_path.endswith(\".docx\"):\n",
    "            return loadDOCS(file_path)\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            return loadTXT(file_path)\n",
    "        elif file_path.endswith(\".csv\"):\n",
    "            return loadCSV(file_path)\n",
    "        elif file_path.endswith(\".md\"):\n",
    "            return loadMD(file_path)\n",
    "        elif file_path.endswith(\".html\"):\n",
    "            return loadHTML(file_path)\n",
    "        elif file_path.endswith(\".json\"):\n",
    "            return loadJSON(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading {file_path}: {e}\")\n",
    "\n",
    "def docData(dir: str = \"file/\"):\n",
    "    documents = []\n",
    "    for file in os.listdir(dir):\n",
    "        file_path = os.path.join(dir, file)\n",
    "        data = load_document(file_path)\n",
    "        if data:\n",
    "            documents.extend(data if isinstance(data, list) else [data])\n",
    "    \n",
    "    print(\"Files loaded successfully\\n\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50bb7255-3316-4c4e-b583-6dc67d4272e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWebsites(file_path: str):\n",
    "    try:\n",
    "        with open(f'{file_path}/websites.txt', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        websites_list = [line.strip() for line in lines]\n",
    "    except Exception as e:\n",
    "        print(\"Error in reading files: \", str(e))\n",
    "    try:\n",
    "        print(\"Websites loaded successfully\\n\")\n",
    "        return loadURL(websites_list)\n",
    "    except Exception as e:\n",
    "        print(\"Error in loading in URLs\\n\")\n",
    "        return f\"Error in loadURL: {e}\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "474118d2-f4e3-47c2-bbf0-2079343498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYoutubeVideos(file_path: str):\n",
    "    try:\n",
    "        with open(f'{file_path}/links.txt', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        links_list = [line.strip() for line in lines]\n",
    "    except Exception as e:\n",
    "        print(\"Error in reading files: \", str(e))\n",
    "    try:\n",
    "        print(\"Youtube Videos loaded successfully\\n\")\n",
    "        return loadYOUTUBE(links_list)\n",
    "    except Exception as e:\n",
    "        print(\"Error in loading in URLs\\n\")\n",
    "        return f\"Error in loadURL: {e}\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "181ba071-ba9e-42e7-8a53-76f2463a2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea856224-b32e-4609-9bce-73cb84b217e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorstore(text_chunks):\n",
    "    # embeddings = OpenAIEmbeddings()\n",
    "    embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66a4da06-9b58-42dd-95c4-ab1326fa871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_localDB():\n",
    "    try:\n",
    "        documents = []\n",
    "        documents.extend(docData(\"userData\"))\n",
    "        documents.extend(loadWebsites(\"userData\"))\n",
    "        documents.extend(loadYoutubeVideos(\"userData\"))\n",
    "\n",
    "        text = \"\"\n",
    "        for docx in documents:\n",
    "            text += (str(docx))\n",
    "\n",
    "        text_chunks = get_text_chunks(text)\n",
    "        db = Chroma.from_texts(text_chunks, embedding=OpenAIEmbeddings(), persist_directory=\"./userData_embedded\")\n",
    "        db.persist()\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(\"Error while creating chroma databse: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2017e581-0138-4105-bfa2-d2e995d3c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_localDB():\n",
    "    try:\n",
    "        db = Chroma(persist_directory=\"./userData_embedded\", embedding_function=OpenAIEmbeddings())\n",
    "        db.get()\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(\"Error while retrieving an embedded database: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de1299f3-870b-41fa-81f6-81f77bf51040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents.extend(docData(\"userData\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3dc929-9461-4f13-bb9e-bf072c42b1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents.extend(loadWebsites(\"userData\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7eb5d8-61e9-4868-b156-25a892a996ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youtube Videos loaded successfully\n",
      "\n",
      "[youtube] Extracting URL: https://youtu.be/lK8gYGg0dkE?feature=shared\n",
      "[youtube] lK8gYGg0dkE: Downloading webpage\n",
      "[youtube] lK8gYGg0dkE: Downloading ios player API JSON\n",
      "[youtube] lK8gYGg0dkE: Downloading android player API JSON\n",
      "[youtube] lK8gYGg0dkE: Downloading m3u8 information\n",
      "[info] lK8gYGg0dkE: Downloading 1 format(s): 140\n",
      "[download] /home/dgxuser16/Downloads/YouTube/President Franklin D. Roosevelt Declares War on Japan (Full Speech) ï½œ War Archives.m4a has already been downloaded\n",
      "[download] 100% of    4.44MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    }
   ],
   "source": [
    "documents.extend(loadYoutubeVideos(\"userData\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef5fc9c-f013-4448-9551-b26c57339d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for docx in documents:\n",
    "    text += (str(docx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45661dca-9cc7-4d13-89aa-53cdc513fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2590, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "chunks = get_text_chunks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604a1658-5a1d-49fa-8169-a7ad3307597c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    }
   ],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277aac6b-38e1-45ef-93e9-0f26bd009f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgxuser16/anaconda3/lib/python3.11/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgxuser16/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "vectordb = get_vectorstore(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b72aa196-79f3-4b3f-8f5b-4715826af9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# localDB = create_localDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ad457be-3599-4ef6-a464-7b066fc2f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadedDB = load_localDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b135d9-a5c2-4a69-a88f-66e7b351b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is the marvel name of Amey Khare?\"\n",
    "# docs = vectordb.similarity_search(query)\n",
    "# # print(docs[0].page_content)\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7312ca89-f5d2-4a1d-9a3c-7ce6a2bbcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=vectordb.as_retriever(),\n",
    "# )\n",
    "\n",
    "# query = \"what is the marvel name for Shivansh Goel?\"\n",
    "# answer = qa_chain.run(query)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a0736cf-f08d-44ec-89f4-83f485916f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driverFunc():\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "    database_folderName = \"userData_embedded\"\n",
    "    current_directory = os.getcwd()\n",
    "    folder_path = os.path.join(current_directory, database_folderName)\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        db = load_localDB()\n",
    "        print(\"Loaded Database Successfully\")\n",
    "    else:\n",
    "        db = create_localDB()\n",
    "        print(\"Created Database Successfully\")\n",
    "    \n",
    "    # documents = []\n",
    "    # documents.extend(docData(\"userData\"))\n",
    "    # documents.extend(loadWebsites(\"userData\"))\n",
    "    # documents.extend(loadYoutubeVideos(\"userData\"))\n",
    "\n",
    "    # text = \"\"\n",
    "    # for docx in documents:\n",
    "    #     text += (str(docx))\n",
    "\n",
    "    # chunks = get_text_chunks(text)\n",
    "    \n",
    "    # db = create_localDB(chunks)\n",
    "    \n",
    "    # qa_chain = RetrievalQA.from_chain_type(\n",
    "    # llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
    "    # chain_type=\"stuff\",\n",
    "    # retriever=db.as_retriever())\n",
    "\n",
    "    # query = input(\"User: \")\n",
    "    # answer = qa_chain.run(query)\n",
    "    # return f\"EngiPal: {answer}\"\n",
    "\n",
    "    pdf_qa = ConversationalRetrievalChain.from_llm(\n",
    "    ChatOpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo\"),\n",
    "    vectordb.as_retriever(search_kwargs={'k': 6}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False)\n",
    "\n",
    "    chat_history = []\n",
    "    print('Welcome to the EngiPal. Your Engineering Pal!\\n')\n",
    "    while True:\n",
    "        query = input(\"Prompt: \")\n",
    "        if query == \"exit\" or query == \"quit\" or query == \"q\" or query == \"f\":\n",
    "            print('Exiting')\n",
    "            return chat_history\n",
    "            sys.exit()\n",
    "        if query == '':\n",
    "            continue\n",
    "        result = pdf_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "        print(\"Answer: \" + result[\"answer\"])\n",
    "        chat_history.append((query, result[\"answer\"]))\n",
    "        \n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b42036c-3392-48a9-a67a-f269200ea747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Database Successfully\n",
      "Welcome to the EngiPal. Your Engineering Pal!\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m chat \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m chat \u001b[38;5;241m=\u001b[39m driverFunc()\n",
      "Cell \u001b[0;32mIn[41], line 45\u001b[0m, in \u001b[0;36mdriverFunc\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWelcome to the EngiPal. Your Engineering Pal!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m query \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m query \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m query \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExiting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1206\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1207\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chat = []\n",
    "chat = driverFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcd7c995-55b9-43da-8b19-61e201e5c4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857485e-6774-4507-bb0d-a15fc1d2983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = driverFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dded5a-b1a1-4d79-b07b-c0262a44637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9020d6-7b6b-4267-83e4-b9e04566a873",
   "metadata": {},
   "source": [
    "EngiPal\n",
    "Checklist:\n",
    "\n",
    "1. Database to store data locally (Completed)\n",
    "2. custom model from huggingface (Completed)\n",
    "3. custom model for embedding (Completed)\n",
    "5. GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817efc82-a555-46d4-a5dc-f0e4d834327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bee7a-3599-4a06-a4a9-56256072d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=\"model/\", device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"model/\")\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5827e-edce-4835-8201-dc7b436ae428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e24be4-714d-45d2-949d-0a6b954f6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f357b58c-009a-4340-a822-c99c449d7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74030600-d916-4e29-80bc-24f725097b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392a970-0f7c-436e-aba6-7e8a42ed8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=mistral_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever())\n",
    "\n",
    "query = input(\"User: \")\n",
    "answer = qa_chain.run(query)\n",
    "print(f\"EngiPal: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "del(tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
