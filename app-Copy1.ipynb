{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf40eb2-6b35-445b-90c7-7747226b7c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from Files.csvLoader import loadCSV\n",
    "from Files.docsLoader import loadDOCS\n",
    "from Files.htmlLoader import loadHTML\n",
    "from Files.jsonLoader import loadJSON\n",
    "from Files.mdLoader import loadMD\n",
    "from Files.pdfLoader import loadPDF\n",
    "from Files.txtLoader import loadTXT\n",
    "\n",
    "from Websites.urlLoader import loadURL\n",
    "from Websites.seleniumLoader import loadSELENIUM\n",
    "from Websites.recursiveLoader import loadRECURSIVE\n",
    "\n",
    "from Videos.youtubeLoader import loadYOUTUBE\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aafc93a2-9a27-47af-9ea3-78a6fc1aa72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad6c0fa-779e-4fea-b58f-85d9eafe42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file_path: str):\n",
    "    try:\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            return loadPDF(file_path)\n",
    "        elif file_path.endswith(\".docx\"):\n",
    "            return loadDOCS(file_path)\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            return loadTXT(file_path)\n",
    "        elif file_path.endswith(\".csv\"):\n",
    "            return loadCSV(file_path)\n",
    "        elif file_path.endswith(\".md\"):\n",
    "            return loadMD(file_path)\n",
    "        elif file_path.endswith(\".html\"):\n",
    "            return loadHTML(file_path)\n",
    "        elif file_path.endswith(\".json\"):\n",
    "            return loadJSON(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error while loading {file_path}: {e}\")\n",
    "\n",
    "def docData(dir: str = \"file/\"):\n",
    "    documents = []\n",
    "    for file in os.listdir(dir):\n",
    "        file_path = os.path.join(dir, file)\n",
    "        data = load_document(file_path)\n",
    "        if data:\n",
    "            documents.extend(data if isinstance(data, list) else [data])\n",
    "    \n",
    "    print(\"Files loaded successfully\\n\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50bb7255-3316-4c4e-b583-6dc67d4272e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadWebsites(file_path: str):\n",
    "    try:\n",
    "        with open(f'{file_path}/websites.txt', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        websites_list = [line.strip() for line in lines]\n",
    "    except Exception as e:\n",
    "        print(\"Error in reading files: \", str(e))\n",
    "    try:\n",
    "        print(\"Websites loaded successfully\\n\")\n",
    "        return loadURL(websites_list)\n",
    "    except Exception as e:\n",
    "        print(\"Error in loading in URLs\\n\")\n",
    "        return f\"Error in loadURL: {e}\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474118d2-f4e3-47c2-bbf0-2079343498f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadYoutubeVideos(file_path: str):\n",
    "    try:\n",
    "        with open(f'{file_path}/links.txt', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        links_list = [line.strip() for line in lines]\n",
    "    except Exception as e:\n",
    "        print(\"Error in reading files: \", str(e))\n",
    "    try:\n",
    "        print(\"Youtube Videos loaded successfully\\n\")\n",
    "        return loadYOUTUBE(links_list)\n",
    "    except Exception as e:\n",
    "        print(\"Error in loading in URLs\\n\")\n",
    "        return f\"Error in loadURL: {e}\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181ba071-ba9e-42e7-8a53-76f2463a2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea856224-b32e-4609-9bce-73cb84b217e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorstore(text_chunks):\n",
    "    # embeddings = OpenAIEmbeddings()\n",
    "    embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a4da06-9b58-42dd-95c4-ab1326fa871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_localDB():\n",
    "    try:\n",
    "        documents = []\n",
    "        documents.extend(docData(\"userData\"))\n",
    "        documents.extend(loadWebsites(\"userData\"))\n",
    "        documents.extend(loadYoutubeVideos(\"userData\"))\n",
    "\n",
    "        text = \"\"\n",
    "        for docx in documents:\n",
    "            text += (str(docx))\n",
    "\n",
    "        text_chunks = get_text_chunks(text)\n",
    "        db = Chroma.from_texts(text_chunks, embedding=OpenAIEmbeddings(), persist_directory=\"./userData_embedded\")\n",
    "        db.persist()\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(\"Error while creating chroma databse: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2017e581-0138-4105-bfa2-d2e995d3c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_localDB():\n",
    "    try:\n",
    "        db = Chroma(persist_directory=\"./userData_embedded\", embedding_function=OpenAIEmbeddings())\n",
    "        db.get()\n",
    "        return db\n",
    "    except Exception as e:\n",
    "        print(\"Error while retrieving an embedded database: \", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1299f3-870b-41fa-81f6-81f77bf51040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents.extend(docData(\"userData\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3dc929-9461-4f13-bb9e-bf072c42b1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Websites loaded successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents.extend(loadWebsites(\"userData\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7eb5d8-61e9-4868-b156-25a892a996ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youtube Videos loaded successfully\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 13:29:54.974413: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-29 13:29:55.009956: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-29 13:29:55.820123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following model:  openai/whisper-large\n",
      "[youtube] Extracting URL: https://youtu.be/lK8gYGg0dkE?feature=shared\n",
      "[youtube] lK8gYGg0dkE: Downloading webpage\n",
      "[youtube] lK8gYGg0dkE: Downloading ios player API JSON\n",
      "[youtube] lK8gYGg0dkE: Downloading android player API JSON\n",
      "[youtube] lK8gYGg0dkE: Downloading m3u8 information\n",
      "[info] lK8gYGg0dkE: Downloading 1 format(s): 140\n",
      "[download] /root/Downloads/YouTube/President Franklin D. Roosevelt Declares War on Japan (Full Speech) ｜ War Archives.m4a has already been downloaded\n",
      "[download] 100% of    4.44MiB\n",
      "[ExtractAudio] Not converting audio /root/Downloads/YouTube/President Franklin D. Roosevelt Declares War on Japan (Full Speech) ｜ War Archives.m4a; file is already in target format m4a\n",
      "[youtube] Extracting URL: https://youtu.be/gjT2NvQo0n4?feature=shared\n",
      "[youtube] gjT2NvQo0n4: Downloading webpage\n",
      "[youtube] gjT2NvQo0n4: Downloading ios player API JSON\n",
      "[youtube] gjT2NvQo0n4: Downloading android player API JSON\n",
      "[youtube] gjT2NvQo0n4: Downloading m3u8 information\n",
      "[info] gjT2NvQo0n4: Downloading 1 format(s): 140\n",
      "[download] /root/Downloads/YouTube/Next Tech Lab ： India's first multi-disciplinary lab.m4a has already been downloaded\n",
      "[download] 100% of    6.73MiB\n",
      "[ExtractAudio] Not converting audio /root/Downloads/YouTube/Next Tech Lab ： India's first multi-disciplinary lab.m4a; file is already in target format m4a\n",
      "Transcribing part /root/Downloads/YouTube/President Franklin D. Roosevelt Declares War on Japan (Full Speech) ｜ War Archives.m4a!\n",
      "Transcribing part /root/Downloads/YouTube/Next Tech Lab ： India's first multi-disciplinary lab.m4a!\n"
     ]
    }
   ],
   "source": [
    "documents.extend(loadYoutubeVideos(\"userData\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ef5fc9c-f013-4448-9551-b26c57339d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for docx in documents:\n",
    "    text += (str(docx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45661dca-9cc7-4d13-89aa-53cdc513fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = get_text_chunks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604a1658-5a1d-49fa-8169-a7ad3307597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277aac6b-38e1-45ef-93e9-0f26bd009f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "vectordb = get_vectorstore(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72aa196-79f3-4b3f-8f5b-4715826af9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# localDB = create_localDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad457be-3599-4ef6-a464-7b066fc2f445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadedDB = load_localDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b135d9-a5c2-4a69-a88f-66e7b351b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What is the marvel name of Amey Khare?\"\n",
    "# docs = vectordb.similarity_search(query)\n",
    "# # print(docs[0].page_content)\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7312ca89-f5d2-4a1d-9a3c-7ce6a2bbcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=vectordb.as_retriever(),\n",
    "# )\n",
    "\n",
    "# query = \"what is the marvel name for Shivansh Goel?\"\n",
    "# answer = qa_chain.run(query)\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0736cf-f08d-44ec-89f4-83f485916f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driverFunc():\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "    database_folderName = \"userData_embedded\"\n",
    "    current_directory = os.getcwd()\n",
    "    folder_path = os.path.join(current_directory, database_folderName)\n",
    "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "        db = load_localDB()\n",
    "        print(\"Loaded Database Successfully\")\n",
    "    else:\n",
    "        db = create_localDB()\n",
    "        print(\"Created Database Successfully\")\n",
    "    \n",
    "    # documents = []\n",
    "    # documents.extend(docData(\"userData\"))\n",
    "    # documents.extend(loadWebsites(\"userData\"))\n",
    "    # documents.extend(loadYoutubeVideos(\"userData\"))\n",
    "\n",
    "    # text = \"\"\n",
    "    # for docx in documents:\n",
    "    #     text += (str(docx))\n",
    "\n",
    "    # chunks = get_text_chunks(text)\n",
    "    \n",
    "    # db = create_localDB(chunks)\n",
    "    \n",
    "    # qa_chain = RetrievalQA.from_chain_type(\n",
    "    # llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0),\n",
    "    # chain_type=\"stuff\",\n",
    "    # retriever=db.as_retriever())\n",
    "\n",
    "    # query = input(\"User: \")\n",
    "    # answer = qa_chain.run(query)\n",
    "    # return f\"EngiPal: {answer}\"\n",
    "\n",
    "    pdf_qa = ConversationalRetrievalChain.from_llm(\n",
    "    ChatOpenAI(temperature=0.9, model_name=\"gpt-3.5-turbo\"),\n",
    "    db.as_retriever(search_kwargs={'k': 6}),\n",
    "    return_source_documents=True,\n",
    "    verbose=False)\n",
    "\n",
    "    chat_history = []\n",
    "    print('Welcome to the EngiPal. Your Engineering Pal!\\n')\n",
    "    while True:\n",
    "        query = input(\"Prompt: \")\n",
    "        if query == \"exit\" or query == \"quit\" or query == \"q\" or query == \"f\":\n",
    "            print('Exiting')\n",
    "            return chat_history\n",
    "            sys.exit()\n",
    "        if query == '':\n",
    "            continue\n",
    "        result = pdf_qa({\"question\": query, \"chat_history\": chat_history})\n",
    "        print(\"Answer: \" + result[\"answer\"])\n",
    "        chat_history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42036c-3392-48a9-a67a-f269200ea747",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = []\n",
    "chat = driverFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd7c995-55b9-43da-8b19-61e201e5c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857485e-6774-4507-bb0d-a15fc1d2983d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = driverFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dded5a-b1a1-4d79-b07b-c0262a44637a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9020d6-7b6b-4267-83e4-b9e04566a873",
   "metadata": {},
   "source": [
    "EngiPal\n",
    "Checklist:\n",
    "\n",
    "1. Database to store data locally (Completed)\n",
    "2. custom model from huggingface (Completed)\n",
    "3. custom model for embedding (Completed)\n",
    "5. GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "817efc82-a555-46d4-a5dc-f0e4d834327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "613bee7a-3599-4a06-a4a9-56256072d0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0e30b35bf54c949e1626cce0e33295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=\"model/\", device_map=\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"model/\")\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ef5827e-edce-4835-8201-dc7b436ae428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07e24be4-714d-45d2-949d-0a6b954f6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f357b58c-009a-4340-a822-c99c449d7d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74030600-d916-4e29-80bc-24f725097b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1392a970-0f7c-436e-aba6-7e8a42ed8311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  explain the day of infamy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EngiPal:  On December 7, 1941, the United States was suddenly and deliberately attacked by the naval and air forces of the Empire of Japan. This event, known as the Day of Infamy, occurred despite the fact that the United States was at peace with Japan and was still in negotiations for maintaining peace in the Pacific. The attack resulted in significant damage to American naval and military forces and led to the loss of many American lives. President Franklin D. Roosevelt addressed the nation and declared that a state of war existed between the United States and the Japanese Empire.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=mistral_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever())\n",
    "\n",
    "query = input(\"User: \")\n",
    "answer = qa_chain.run(query)\n",
    "print(f\"EngiPal: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc17672-4ff8-488f-afa1-13e8c80b8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(model)\n",
    "del(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68720bc6-f670-49b4-9fa8-7149a56b193a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
